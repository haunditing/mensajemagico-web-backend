const { GoogleGenerativeAI } = require("@google/generative-ai");
const crypto = require("crypto");
const logger = require("../utils/logger");
const RegionalContextService = require("./RegionalContextService");
const SystemUsage = require("../models/SystemUsage");

const genAI = new GoogleGenerativeAI(process.env.AI_API_KEY);

const responseCache = new Map();
const CACHE_TTL_MS = 1000 * 60 * 60;

const generate = async (aiConfig, data) => {
  const {
    occasion,
    tone,
    contextWords,
    relationship,
    receivedText,
    formatInstruction,
    userLocation,
    planLevel,
    neutralMode,
    snoozeCount = 0,
    relationalHealth = 5,
    modelOverride,
  } = data;

  // 1. GESTI칍N DE CACH칄
  const cacheKey = crypto
    .createHash("md5")
    .update(JSON.stringify(data, Object.keys(data).sort()))
    .digest("hex");

  if (responseCache.has(cacheKey)) {
    const { text, timestamp } = responseCache.get(cacheKey);
    if (Date.now() - timestamp < CACHE_TTL_MS) return text;
    responseCache.delete(cacheKey);
  }

  // 2. CONSTRUCCI칍N DE CONTEXTO REGIONAL
  const regionalBoost = RegionalContextService.getRegionalBoost(
    userLocation,
    planLevel,
    neutralMode,
  );

  // 3. CONSTRUCCI칍N DEL SYSTEM INSTRUCTION (Reglas de Oro)
  const systemInstructionText = `
    ### ROLE
    Act칰as como el "Guardi치n de Sentimiento", un motor de inteligencia emocional. Tu misi칩n es transformar recordatorios fr칤os en conexiones humanas significativas, priorizando la cultura de Cartagena y la Costa Caribe si el contexto lo permite.

    ### OPERATING MODES
    #### 1. MODO AN츼LISIS (Para todos los planes)
    - Analiza la salud de la relaci칩n (Salud: ${relationalHealth}/10). Si es < 4, usa tono de "Recuperaci칩n de V칤nculo" (humilde, sin presi칩n).
    - Si SnoozeCount (${snoozeCount}) > 1, reconoce la demora de forma natural.

    #### 2. MODO ESTRATEGIA (Diferenciaci칩n)
    - **Si Plan == GUEST/FREEMIUM:** Mensaje est치ndar y breve + GUARDIAN_INSIGHT (consejo de valor sin clich칠s).
    - **Si Plan == PREMIUM:** ADN Regional (Carisma caribe침o sofisticado), Estrategia de Regalo local y An치lisis Psicol칩gico de la elecci칩n del tono.

    ### CONSTRAINTS
    - Prohibido sonar rob칩tico. Max 500 tokens.
    - ${aiConfig.prompt_style || "Act칰a como un asistente de mensajer칤a."} 
    - ${aiConfig.length_instruction || ""}
  `.trim();

  // 4. CONSTRUCCI칍N DEL PROMPT DE USUARIO
  const promptText = `
    ### INPUT DATA
    - UserPlan: ${planLevel ? planLevel.toUpperCase() : "GUEST"}
    - RelationalHealth: ${relationalHealth}/10
    - Region: ${userLocation || "Desconocida"}
    - Occasion: ${occasion}
    - Relationship: ${relationship || "General"}
    - Tone: ${tone}
    - Context: ${contextWords || "Ninguno"}
    - ReceivedText: ${receivedText || "N/A"}
    - RegionalContext: ${regionalBoost}

    ${formatInstruction || ""}
  `.trim();

  try {
    const selectedModel = modelOverride || aiConfig.model || "gemini-1.5-flash";

    // 游녣 SOLUCI칍N AL ERROR 400 (Compatibilidad Gemma)
    // Gemma NO acepta 'systemInstruction'. Si es Gemma, inyectamos las reglas en el prompt.
    const isGemma = selectedModel.toLowerCase().includes("gemma");

    let model;
    let finalPrompt;

    if (isGemma) {
      model = genAI.getGenerativeModel({ model: selectedModel });
      finalPrompt = `[SYSTEM_RULES]\n${systemInstructionText}\n\n[USER_REQUEST]\n${promptText}`;
    } else {
      model = genAI.getGenerativeModel({
        model: selectedModel,
        systemInstruction: systemInstructionText,
      });
      finalPrompt = promptText;
    }

    // 5. CONFIGURACI칍N DE GENERACI칍N Y SEGURIDAD
    const generationConfig = {
      temperature: aiConfig.temperature || 0.7,
      topP: 0.95,
      topK: 40,
    };

    const safetySettings = [
      { category: "HARM_CATEGORY_HARASSMENT", threshold: "BLOCK_ONLY_HIGH" },
      { category: "HARM_CATEGORY_HATE_SPEECH", threshold: "BLOCK_ONLY_HIGH" },
      {
        category: "HARM_CATEGORY_SEXUALLY_EXPLICIT",
        threshold: "BLOCK_ONLY_HIGH",
      },
      {
        category: "HARM_CATEGORY_DANGEROUS_CONTENT",
        threshold: "BLOCK_ONLY_HIGH",
      },
    ];

    // 6. EJECUCI칍N
    const result = await model.generateContent({
      contents: [{ role: "user", parts: [{ text: finalPrompt }] }],
      generationConfig,
      safetySettings,
    });

    const response = await result.response;
    const generatedText = response.text();

    // 7. PERSISTENCIA Y M칄TRICAS
    responseCache.set(cacheKey, {
      text: generatedText,
      timestamp: Date.now(),
    });

    // Registrar uso del modelo para el orquestador
    await SystemUsage.increment(selectedModel);

    return generatedText;
  } catch (error) {
    logger.error("Error en AIService", {
      model: modelOverride,
      error: error.message,
      stack: error.stack,
    });

    // Si el error es de cuota (429), lo lanzamos para que el Controller active el fallback
    if (error.message.includes("429") || error.message.includes("quota")) {
      const quotaError = new Error("QUOTA_EXCEEDED");
      quotaError.statusCode = 429;
      throw quotaError;
    }

    throw new Error("La IA no pudo completar la solicitud en este momento.");
  }
};

module.exports = { generate };
